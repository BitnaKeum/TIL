{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS     = 300\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('./.data',\n",
    "                   train=True,\n",
    "                   download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.RandomCrop(32, padding=4),\n",
    "                       transforms.RandomHorizontalFlip(),\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                            (0.5, 0.5, 0.5))])),\n",
    "                   batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('./.data',\n",
    "                   train=False, \n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                            (0.5, 0.5, 0.5))])),\n",
    "                   batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(16, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(32, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(64, 2, stride=2)\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "    def _make_layer(self, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(BasicBlock(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet().to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1,\n",
    "                      momentum=0.9, weight_decay=0.0005)\n",
    "optimizer.step()\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "\n",
    "            # 배치 오차를 합산\n",
    "            test_loss += F.cross_entropy(output, target,\n",
    "                                         reduction='sum').item()\n",
    "\n",
    "            # 가장 높은 값을 가진 인덱스가 바로 예측값\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beaus\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Test Loss: 1.7131, Accuracy: 43.25%\n",
      "[2] Test Loss: 1.2474, Accuracy: 56.59%\n",
      "[3] Test Loss: 1.1505, Accuracy: 61.57%\n",
      "[4] Test Loss: 0.8563, Accuracy: 70.13%\n",
      "[5] Test Loss: 0.8173, Accuracy: 72.76%\n",
      "[6] Test Loss: 0.7767, Accuracy: 74.00%\n",
      "[7] Test Loss: 0.8505, Accuracy: 71.83%\n",
      "[8] Test Loss: 0.9174, Accuracy: 71.00%\n",
      "[9] Test Loss: 0.7755, Accuracy: 74.09%\n",
      "[10] Test Loss: 0.7690, Accuracy: 74.78%\n",
      "[11] Test Loss: 0.9025, Accuracy: 70.82%\n",
      "[12] Test Loss: 0.7015, Accuracy: 76.66%\n",
      "[13] Test Loss: 0.6532, Accuracy: 78.74%\n",
      "[14] Test Loss: 0.7054, Accuracy: 76.22%\n",
      "[15] Test Loss: 0.9425, Accuracy: 69.06%\n",
      "[16] Test Loss: 0.7019, Accuracy: 75.94%\n",
      "[17] Test Loss: 0.6624, Accuracy: 78.24%\n",
      "[18] Test Loss: 0.9451, Accuracy: 71.13%\n",
      "[19] Test Loss: 0.6953, Accuracy: 77.55%\n",
      "[20] Test Loss: 0.6456, Accuracy: 78.34%\n",
      "[21] Test Loss: 1.0107, Accuracy: 70.75%\n",
      "[22] Test Loss: 1.0473, Accuracy: 70.83%\n",
      "[23] Test Loss: 0.5585, Accuracy: 81.40%\n",
      "[24] Test Loss: 0.7494, Accuracy: 76.64%\n",
      "[25] Test Loss: 0.6023, Accuracy: 79.76%\n",
      "[26] Test Loss: 0.7577, Accuracy: 74.88%\n",
      "[27] Test Loss: 0.7546, Accuracy: 75.31%\n",
      "[28] Test Loss: 0.6245, Accuracy: 79.16%\n",
      "[29] Test Loss: 0.7721, Accuracy: 75.15%\n",
      "[30] Test Loss: 0.5457, Accuracy: 81.18%\n",
      "[31] Test Loss: 0.7924, Accuracy: 74.09%\n",
      "[32] Test Loss: 0.7456, Accuracy: 74.93%\n",
      "[33] Test Loss: 0.6621, Accuracy: 77.90%\n",
      "[34] Test Loss: 0.7171, Accuracy: 77.20%\n",
      "[35] Test Loss: 0.6752, Accuracy: 78.20%\n",
      "[36] Test Loss: 0.5899, Accuracy: 79.63%\n",
      "[37] Test Loss: 0.6494, Accuracy: 78.17%\n",
      "[38] Test Loss: 0.6791, Accuracy: 78.46%\n",
      "[39] Test Loss: 0.6494, Accuracy: 78.52%\n",
      "[40] Test Loss: 0.8026, Accuracy: 74.53%\n",
      "[41] Test Loss: 0.8494, Accuracy: 71.56%\n",
      "[42] Test Loss: 0.8862, Accuracy: 73.02%\n",
      "[43] Test Loss: 1.0251, Accuracy: 70.02%\n",
      "[44] Test Loss: 0.6487, Accuracy: 78.35%\n",
      "[45] Test Loss: 0.8130, Accuracy: 72.79%\n",
      "[46] Test Loss: 0.6913, Accuracy: 77.09%\n",
      "[47] Test Loss: 0.6371, Accuracy: 79.04%\n",
      "[48] Test Loss: 0.5662, Accuracy: 81.37%\n",
      "[49] Test Loss: 0.7593, Accuracy: 75.41%\n",
      "[50] Test Loss: 0.3381, Accuracy: 88.33%\n",
      "[51] Test Loss: 0.3378, Accuracy: 88.17%\n",
      "[52] Test Loss: 0.3222, Accuracy: 88.90%\n",
      "[53] Test Loss: 0.3259, Accuracy: 88.89%\n",
      "[54] Test Loss: 0.3239, Accuracy: 88.99%\n",
      "[55] Test Loss: 0.3229, Accuracy: 89.00%\n",
      "[56] Test Loss: 0.3282, Accuracy: 89.04%\n",
      "[57] Test Loss: 0.3232, Accuracy: 89.27%\n",
      "[58] Test Loss: 0.3189, Accuracy: 89.33%\n",
      "[59] Test Loss: 0.3327, Accuracy: 88.94%\n",
      "[60] Test Loss: 0.3395, Accuracy: 89.16%\n",
      "[61] Test Loss: 0.3250, Accuracy: 89.24%\n",
      "[62] Test Loss: 0.3261, Accuracy: 89.04%\n",
      "[63] Test Loss: 0.3389, Accuracy: 88.60%\n",
      "[64] Test Loss: 0.3255, Accuracy: 89.14%\n",
      "[65] Test Loss: 0.3327, Accuracy: 89.11%\n",
      "[66] Test Loss: 0.3143, Accuracy: 89.25%\n",
      "[67] Test Loss: 0.3310, Accuracy: 89.17%\n",
      "[68] Test Loss: 0.3573, Accuracy: 88.38%\n",
      "[69] Test Loss: 0.4002, Accuracy: 87.04%\n",
      "[70] Test Loss: 0.3696, Accuracy: 88.00%\n",
      "[71] Test Loss: 0.3545, Accuracy: 88.88%\n",
      "[72] Test Loss: 0.3380, Accuracy: 89.00%\n",
      "[73] Test Loss: 0.3431, Accuracy: 88.94%\n",
      "[74] Test Loss: 0.3738, Accuracy: 88.09%\n",
      "[75] Test Loss: 0.3723, Accuracy: 88.02%\n",
      "[76] Test Loss: 0.3491, Accuracy: 88.80%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    scheduler.step()\n",
    "    train(model, train_loader, optimizer, epoch)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    \n",
    "    print('[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(\n",
    "          epoch, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
